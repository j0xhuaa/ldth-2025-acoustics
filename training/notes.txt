CHECKPOINT: Trained the model on log mel spectrograms and saved to disk, as a basic starting point.
(Also created a mini streamlit dashboard for viewing the spectrograms, mostly to assist with conceptualising audio data.)

NEXT: Evaluate the model against the test data, and determine performance on unseen samples.
(Train a model on 1D waveform array and compare performance)
(Depending on performance, trial an ensemble model, trained on both, or a third feature)
(Add a creative streamlit component that visually classifies the audio on a dashboard for an operator potentially vibe code that in flask)

Evaluation of model_logmel_cnn_v1.0.h5

Test Accuracy: 0.9655
- 96.55% of predictions were correct on X_test dataset
- Generalizes well on unseen data,

Test Loss: 0.1037
- Cross entropy loss, which quantifies the difference between the predicted probablities and the actual labels
- The loss is reasonable here, as even with a high accuracy a high loss can mean there is some error spread across classes.
- Can be considered as a confidence penalty.

Classification Report
- precision: of all the times the model predicted this class, how many were actually correct
- recall: of all the actual samples of this class, how many did the model correctly identify
- f1-score: Balance between precision and recall
- support: the number of true examples of this class in the rest set
The classification report:
              precision    recall  f1-score   support

           0       0.94      0.94      0.94        16
           1       0.96      0.96      0.96        24
           2       1.00      1.00      1.00        18

    accuracy                           0.97        58
   macro avg       0.97      0.97      0.97        58
weighted avg       0.97      0.97      0.97        58